import asyncio
import os
from dotenv import load_dotenv
from openai import AsyncOpenAI

load_dotenv()

class LanguageModelProcessor:
    def __init__(self):
        openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
        
        if not openrouter_api_key:
            raise ValueError("OPENROUTER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

        self.client = AsyncOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=openrouter_api_key,
        )
        
        self.model = "meta-llama/llama-3.1-70b-instruct"
        self.conversation_history = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        try:
            with open('Bot_prompt.txt', 'r', encoding='utf-8') as file:
                self.system_prompt = file.read().strip()
        except FileNotFoundError:
            raise FileNotFoundError("–§–∞–π–ª 'Bot_prompt.txt' –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    async def process(self, text: str) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM."""
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        messages.extend(self.conversation_history)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        messages.append({"role": "user", "content": text})
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=1000
            )
            
            assistant_message = response.choices[0].message.content
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            self.conversation_history.append({"role": "user", "content": text})
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 20 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (10 –ø–∞—Ä)
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            return assistant_message
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API: {str(e)}"

class ConversationManager:
    def __init__(self):
        self.llm_processor = LanguageModelProcessor()
        print()
        print("ü§ñ Chat bot initialized. Type 'goodbye' to exit.")
        print()

    async def main(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."""
        while True:
            user_input = input("–í—ã: ").strip()

            if not user_input:
                continue

            if user_input.lower() in ["exit", "quit", "goodbye"]:
                print("ü§ñ: Goodbye!")
                break

            try:
                llm_response = await self.llm_processor.process(user_input)
                print(f"ü§ñ: {llm_response}")
                print()
            except Exception as e:
                print(f"‚ùå Error: {e}")

if __name__ == "__main__":
    manager = ConversationManager()
    asyncio.run(manager.main())
