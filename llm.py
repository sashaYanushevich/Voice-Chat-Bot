import os
import asyncio
from dotenv import load_dotenv
from openai import AsyncOpenAI

# Load environment variables (e.g., OPENROUTER_API_KEY)
load_dotenv()

class OpenRouterClient:
    def __init__(self, model: str = "openai/gpt-4.1"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–ª–∏–µ–Ω—Ç OpenRouter —Å –º–æ–¥–µ–ª—å—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
        """
        self.client = AsyncOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=os.getenv("OPENROUTER_API_KEY"),
        )
        self.model = model
        self.conversation_history = []
        self.interview_completed = False  # –§–ª–∞–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é

    async def chat_completion(self, user_message: str, system_message: str = None) -> tuple[str, bool]:
        """
        –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ OpenRouter API –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç —Å —Ñ–ª–∞–≥–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (response_text, is_interview_ended)
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é
        if self.interview_completed:
            return "Thank you for completing the screening interview. Our recruitment team will be in touch soon to discuss the next steps. Enjoy the rest of your day!", True
        
        messages = []
        
        if system_message:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–ª—è –º–µ—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            enhanced_system_message = f"""{system_message}

INTERVIEW COMPLETION INSTRUCTIONS:
When you have finished asking all your interview questions and are ready to end the interview, you MUST include the special marker [INTERVIEW_END] at the very beginning of your final response.

Example: "[INTERVIEW_END] Thank you for completing the screening interview. Our recruitment team will be in touch soon to discuss the next steps. Enjoy the rest of your day!"

This marker will signal the system to automatically end the interview session."""
            messages.append({"role": "system", "content": enhanced_system_message})
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        messages.extend(self.conversation_history)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        messages.append({"role": "user", "content": user_message})
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=500
            )
            
            assistant_message = response.choices[0].message.content
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é
            interview_ended = False
            if assistant_message.startswith("[INTERVIEW_END]"):
                interview_ended = True
                self.interview_completed = True
                # –£–±–∏—Ä–∞–µ–º –º–µ—Ç–∫—É –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                assistant_message = assistant_message.replace("[INTERVIEW_END]", "").strip()
                print("üéØ Interview completion marker detected!")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            self.conversation_history.append({"role": "user", "content": user_message})
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 10 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (5 –ø–∞—Ä)
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
            
            return assistant_message, interview_ended
            
        except Exception as e:
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API: {str(e)}", False

    async def stream_completion(self, user_message: str, system_message: str = None):
        """
        –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞.
        """
        messages = []
        
        if system_message:
            messages.append({"role": "system", "content": system_message})
        
        messages.extend(self.conversation_history)
        messages.append({"role": "user", "content": user_message})
        
        try:
            stream = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=500,
                stream=True
            )
            
            assistant_message = ""
            async for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    assistant_message += content
                    yield content
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.conversation_history.append({"role": "user", "content": user_message})
            self.conversation_history.append({"role": "assistant", "content": assistant_message})
            
            if len(self.conversation_history) > 10:
                self.conversation_history = self.conversation_history[-10:]
                
        except Exception as e:
            yield f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API: {str(e)}"

    def clear_history(self):
        """–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."""
        self.conversation_history = []
        self.interview_completed = False
    
    def is_interview_completed(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é."""
        return self.interview_completed
    
    def get_interview_status(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∏–Ω—Ç–µ—Ä–≤—å—é."""
        return {
            'completed': self.interview_completed,
            'conversation_length': len(self.conversation_history)
        }

async def run_batch_example():
    """
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ batch —Ä–µ–∂–∏–º–µ.
    """
    client = OpenRouterClient()
    user_input = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
    
    system_prompt = "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –ª–∞–∫–æ–Ω–∏—á–Ω–æ –∏ –ø–æ –¥–µ–ª—É."
    
    response = await client.chat_completion(user_input, system_prompt)
    print(f"\nResponse: {response}")



