import asyncio
import os
import shutil
import subprocess
import sys
import time
from typing import Optional

import requests
from dotenv import load_dotenv
from deepgram import (DeepgramClient, DeepgramClientOptions, LiveOptions,
                     LiveTranscriptionEvents, Microphone)
from openai import AsyncOpenAI

load_dotenv()

class Config:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è."""
    def __init__(self):
        self.openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
        self.deepgram_api_key = os.getenv("DEEPGRAM_API_KEY")
        
        # –ú–æ–¥–µ–ª–∏
        self.llm_model = "meta-llama/llama-3.1-70b-instruct"
        self.stt_model = "nova-2"
        self.tts_model = "aura-helios-en"
        
        # –ü—É—Ç–∏ —Ñ–∞–π–ª–æ–≤
        self.bot_prompt_file = "Bot_prompt.txt"
        
        self._validate()

    def _validate(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π."""
        if not self.openrouter_api_key:
            raise ValueError("–û–®–ò–ë–ö–ê: OPENROUTER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        if not self.deepgram_api_key:
            raise ValueError("–û–®–ò–ë–ö–ê: DEEPGRAM_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
        if not os.path.exists(self.bot_prompt_file):
            raise FileNotFoundError(f"–û–®–ò–ë–ö–ê: –§–∞–π–ª –ø—Ä–æ–º–ø—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: '{self.bot_prompt_file}'")
        if not self._is_installed("ffplay"):
            raise RuntimeError("–û–®–ò–ë–ö–ê: ffplay –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ffmpeg –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –∞—É–¥–∏–æ.")

    @staticmethod
    def _is_installed(lib_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —É—Ç–∏–ª–∏—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏."""
        return shutil.which(lib_name) is not None

# --- –ö–ª–∞—Å—Å—ã —Å–µ—Ä–≤–∏—Å–æ–≤ ---

class LiveTranscriber:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é —Ä–µ—á–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –ø–æ–º–æ—â—å—é Deepgram."""
    def __init__(self, config: Config):
        client_config = DeepgramClientOptions(options={"keepalive": "true"})
        self.client = DeepgramClient(config.deepgram_api_key, client_config)
        self.stt_model = config.stt_model
        self.transcript_future: Optional[asyncio.Future] = None

    async def listen(self) -> str:
        """
        –°–ª—É—à–∞–µ—Ç –æ–¥–Ω–æ –ø–æ–ª–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ.
        """
        self.transcript_future = asyncio.Future()
        
        connection = self.client.listen.asynclive.v("1")
        connection.on(LiveTranscriptionEvents.Transcript, self._on_message)
        connection.on(LiveTranscriptionEvents.Error, self._on_error)

        options = LiveOptions(
            model=self.stt_model,
            language="en-US",
            punctuate=True,
            encoding="linear16",
            channels=1,
            sample_rate=16000,
            endpointing=200,  # –£–º–µ–Ω—å—à–∞–µ–º –≤—Ä–µ–º—è —Ç–∏—à–∏–Ω—ã –¥–ª—è –ª—É—á—à–µ–π –æ—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç–∏
            smart_format=True,
            interim_results=False,
        )
        await connection.start(options)
        
        microphone = Microphone(connection.send)
        microphone.start()

        try:
            final_transcript = await self.transcript_future
            return final_transcript
        finally:
            microphone.finish()
            await connection.finish()

    async def _on_message(self, _, result, **kwargs):
        """–û–±—Ä–∞—Ç–Ω—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –æ—Ç Deepgram."""
        if result.is_final and result.channel.alternatives[0].transcript.strip():
            transcript = result.channel.alternatives[0].transcript
            if self.transcript_future and not self.transcript_future.done():
                self.transcript_future.set_result(transcript)

    async def _on_error(self, _, error, **kwargs):
        """–û–±—Ä–∞—Ç–Ω—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è."""
        print(f"\nSTT Error: {error}\n")
        if self.transcript_future and not self.transcript_future.done():
            self.transcript_future.set_exception(Exception(f"–û—à–∏–±–∫–∞ STT: {error}"))

class LLMProcessor:
    """–£–ø—Ä–∞–≤–ª—è–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ–º —Å —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª—å—é —á–µ—Ä–µ–∑ OpenRouter."""
    def __init__(self, config: Config):
        self.client = AsyncOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=config.openrouter_api_key,
        )
        self.model = config.llm_model
        self.conversation_history = []
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        with open(config.bot_prompt_file, 'r', encoding='utf-8') as f:
            self.system_prompt = f.read().strip()

    async def generate_response(self, user_text: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞."""
        start_time = time.time()
        
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        messages.extend(self.conversation_history)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        messages.append({"role": "user", "content": user_text})
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                max_tokens=500  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            )
            
            ai_response = response.choices[0].message.content
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            self.conversation_history.append({"role": "user", "content": user_text})
            self.conversation_history.append({"role": "assistant", "content": ai_response})
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 20 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (10 –ø–∞—Ä)
            if len(self.conversation_history) > 20:
                self.conversation_history = self.conversation_history[-20:]
            
            end_time = time.time()
            elapsed_ms = int((end_time - start_time) * 1000)
            
            print(f"LLM ({elapsed_ms}ms): {ai_response}")
            return ai_response
            
        except Exception as e:
            error_msg = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLM: {str(e)}"
            print(error_msg)
            return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."

class SpeechSynthesizer:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å —Å –ø–æ–º–æ—â—å—é AWS Polly."""
    def __init__(self, config: Config):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º AWS TTS
        from aws_tts import AWSPollyTTS
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è AWS Polly
        voice_id = getattr(config, 'aws_voice_id', 'Salli')  # –∏–ª–∏ 'Matthew', 'Salli'
        region = getattr(config, 'aws_region', 'us-east-1')
        chunk_size = getattr(config, 'tts_chunk_size', 30)
        
        try:
            self.tts = AWSPollyTTS(
                voice_id=voice_id,
                region_name=region,
                chunk_size=chunk_size
            )
        except Exception as e:
            print(f"‚ùå AWS Polly initialization error: {e}")
            print("üí° Fallback to Deepgram TTS...")
            # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π Deepgram TTS
            self._init_deepgram_fallback(config)

    def _init_deepgram_fallback(self, config):
        """Fallback –Ω–∞ Deepgram TTS –µ—Å–ª–∏ AWS Polly –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."""
        self.tts = None
        self.api_key = config.deepgram_api_key
        self.model_name = config.tts_model
        self.api_url = f"https://api.deepgram.com/v1/speak?model={self.model_name}&encoding=linear16&sample_rate=24000"

    async def speak(self, text: str):
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ä–µ—á—å –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç."""
        if hasattr(self, 'tts') and self.tts:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º AWS Polly —Å chunking
            await self.tts.speak(text)
        else:
            # Fallback –Ω–∞ Deepgram
            await self._speak_deepgram(text)

    async def _speak_deepgram(self, text: str):
        """Fallback –º–µ—Ç–æ–¥ —Å Deepgram TTS."""
        headers = {"Authorization": f"Token {self.api_key}", "Content-Type": "application/json"}
        payload = {"text": text}
        
        player_command = ["ffplay", "-autoexit", "-", "-nodisp", "-loglevel", "quiet"]
        player_process = subprocess.Popen(
            player_command,
            stdin=subprocess.PIPE,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )

        request_start_time = time.time()
        
        try:
            import requests
            with requests.post(self.api_url, stream=True, headers=headers, json=payload, timeout=20) as response:
                response.raise_for_status()
                first_byte_received = False
                for chunk in response.iter_content(chunk_size=1024):
                    if chunk:
                        if not first_byte_received:
                            ttfb = int((time.time() - request_start_time) * 1000)
                            print(f"TTS TTFB: {ttfb}ms")
                            first_byte_received = True
                        player_process.stdin.write(chunk)
                        player_process.stdin.flush()
        except Exception as e:
            print(f"Deepgram TTS error: {e}")
        finally:
            if player_process.stdin:
                player_process.stdin.close()
            player_process.wait()

# --- –ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è ---

class VoiceAssistant:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —É–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ—Ç–æ–∫–æ–º —Ä–∞–∑–≥–æ–≤–æ—Ä–∞."""
    TERMINATION_PHRASES = ["goodbye", "exit", "quit", "stop", "bye"]

    def __init__(self, config: Config):
        self.transcriber = LiveTranscriber(config)
        self.llm_processor = LLMProcessor(config)
        self.synthesizer = SpeechSynthesizer(config)

    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
        print("--- üé§ Voice Assistant Activated ---")
        print(f"Say any of these phrases to exit: {', '.join(self.TERMINATION_PHRASES)}")
        
        while True:
            try:
                print("\nüéß Listening...")
                user_text = await self.transcriber.listen()
                
                if not user_text:
                    continue
                    
                print(f"üë§ Human: {user_text}")

                # Check for termination phrases
                if any(phrase in user_text.lower().strip() for phrase in self.TERMINATION_PHRASES):
                    print("Termination phrase detected. Shutting down.")
                    goodbye_message = "Goodbye! Have a great day!"
                    print(f"ü§ñ AI: {goodbye_message}")
                    await self.synthesizer.speak(goodbye_message)
                    break

                ai_response = await self.llm_processor.generate_response(user_text)
                await self.synthesizer.speak(ai_response)
                
            except Exception as e:
                print(f"Error in main loop: {e}")
                print("Restarting listening loop...")
                await asyncio.sleep(1)

async def main():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞."""
    try:
        config = Config()
        assistant = VoiceAssistant(config)
        await assistant.run()
    except (ValueError, FileNotFoundError, RuntimeError) as e:
        print(f"Configuration error: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\n--- üõë Assistant deactivated by user ---")
    except Exception as e:
        print(f"Unexpected critical error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
